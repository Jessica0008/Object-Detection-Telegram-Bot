{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пример object detection \n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torch import tensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем модель fasterrcnn_resnet50 с классами MS COCO из интернета\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для рисования рамки\n",
    "def plot_preds(numpy_img, preds):\n",
    "    boxes = preds['boxes'].detach().numpy()\n",
    "    for box in boxes:\n",
    "        numpy_img = cv2.rectangle(numpy_img,\n",
    "            (box[0],box[1]),\n",
    "            (box[2],box[3]),\n",
    "            255,\n",
    "            3\n",
    "            )\n",
    "    return numpy_img #.get()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 195, 598])\n"
     ]
    }
   ],
   "source": [
    "# переводим модель в тестовый режим\n",
    "model = model.eval()\n",
    "# загружаем картинку через со стандартным преобразованием цветов\n",
    "img_numpy = cv2.imread('./humans.png')[:,:,::-1]\n",
    "# преобразуем картинку в torch тензор \n",
    "img = torch.from_numpy(img_numpy.astype('float32')).permute(2,0,1)\n",
    "# приводим масштаб цветов к (0. , 1.)\n",
    "img = img / 255.\n",
    "print(img.shape)\n",
    "# нейросеть предсказывает, что находится на картинке и обводит распознанные обьекты рамкой\n",
    "predictions = model(img[None,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'boxes': tensor([[ 14.3158,   8.5602, 115.0791, 253.4381],\n",
      "        [337.6098,   6.8511, 413.7230, 252.0428],\n",
      "        [589.7033,  10.0957, 650.2061, 254.9260],\n",
      "        [267.3442,  17.3030, 333.6946, 255.5823],\n",
      "        [193.6680,   8.1310, 260.7060, 253.6028],\n",
      "        [422.2102,  11.4213, 487.8574, 251.0170],\n",
      "        [120.9018,   8.2388, 180.7693, 253.7675],\n",
      "        [731.1128,  14.4665, 791.8784, 251.6598],\n",
      "        [499.1318,   9.7717, 578.4976, 256.2612],\n",
      "        [801.2465,  11.2990, 867.4915, 254.3067],\n",
      "        [874.3609,   4.9784, 962.2171, 258.6138],\n",
      "        [664.0148,   9.2175, 726.6874, 254.3811],\n",
      "        [541.6831,  56.8325, 548.5520,  76.6581],\n",
      "        [352.5661,  44.4072, 400.7342, 113.8593],\n",
      "        [529.5683,  55.9454, 542.2265,  80.2307],\n",
      "        [355.6401,  46.0096, 400.2527, 117.5899],\n",
      "        [534.0168,   9.3423, 794.2749, 258.2900],\n",
      "        [222.7823,   9.0249, 468.1794, 259.5898],\n",
      "        [683.7505, 119.4585, 702.8557, 128.5564],\n",
      "        [742.5016,  95.3334, 784.0098, 160.1787],\n",
      "        [618.4193,  78.7107, 648.6172, 101.0402],\n",
      "        [531.7226,  55.7346, 539.7444,  73.0866],\n",
      "        [362.2651,   3.2602, 447.2776, 252.1919],\n",
      "        [137.7130,   6.6376, 227.7212, 256.5672],\n",
      "        [827.4153, 113.1703, 852.5235, 148.6268],\n",
      "        [534.2393,  56.1434, 548.5322,  76.9980],\n",
      "        [147.8823, 122.8611, 163.1157, 144.0873],\n",
      "        [690.1954,   4.3016, 780.4852, 260.3157],\n",
      "        [737.7817,  54.7182, 747.6222,  65.0538],\n",
      "        [496.4438,  62.9539, 522.4686, 143.9461],\n",
      "        [449.4165,  10.7034, 689.9045, 258.4150],\n",
      "        [529.8081,  53.4524, 537.9355,  65.0633],\n",
      "        [379.4090,  48.3505, 406.3031, 122.1000],\n",
      "        [682.2076,  12.4843, 920.0244, 256.6456],\n",
      "        [514.6898,  47.5552, 544.9980, 133.4984]]), 'labels': tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 32, 27, 32, 31,  1,  1,\n",
      "        77, 31, 84, 32,  1,  1, 31, 32, 34,  1, 77, 31,  1, 32, 31,  1, 32]), 'scores': tensor([0.9995, 0.9994, 0.9992, 0.9992, 0.9991, 0.9991, 0.9990, 0.9990, 0.9988,\n",
      "        0.9988, 0.9987, 0.9985, 0.8771, 0.7779, 0.4971, 0.3355, 0.1569, 0.1427,\n",
      "        0.1387, 0.1075, 0.1026, 0.0980, 0.0979, 0.0914, 0.0753, 0.0718, 0.0704,\n",
      "        0.0689, 0.0675, 0.0638, 0.0630, 0.0612, 0.0592, 0.0576, 0.0516])}]\n"
     ]
    }
   ],
   "source": [
    "# Попробовать разобраться, как посчитать распознанные предметы \n",
    "# словарь содержит boxes - рамки, labels - названия, и scores - вероятности (label = 1 - человек)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
